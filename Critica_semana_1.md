# Crítica de "Collaborative Filtering Recommender Systems"
### Autores del paper: Schafer, J. B., Frankowski, D., Herlocker, J., & Sen, S.

## Resumen:
Este paper habla de los distintos tipos de Collaborative Filtering, luego de dar una explicación de lo que se define como tal, y habla sobre las ventajas, mejoras aplicadas, y desventajas de cada uno. Esto último lo hace no sólo desde un punto de vista de algoritmos, si no que tomando en cuenta el comportamiento de los usuarios participantes del CF.

## Reseña:
Me pareció un paper muy interesante, ya que desde un comienzo habla de problemas no siempre considerados cuando se habla de sistemas recomendadores. Un ejemplo claro de esto, es cuando habla de que en un sistema con una calificación con escala (por ejemlo, del 1 al 5), dos usuarios le pueden dar calificaciones diferentes a una misma película ya que para ellos cada calificación puede tener un significado diferente. Es decir, uno puede darle 4 estrellas a una película que le gustó mucho, mientras el otro le puede dar sólo 3. También me gusta que se le haya dado una solución matemática a estos problemas presentados. En el caso previamente mencionado, esto se resuelve usando la correlación Pearson, que compara cómo se ve la calificación del item del usuario en relación a sus otras calificaciones. De esta forma se puede eliminar esa diferencia de percepción. Esto en teoría, ya que esta correlación no toma en cuenta los usuarios que sólo califican las cosas que les gustan, ya que pierden el interés en las que les disgustan; o completamente lo opuesto: aquellos que sólo dejan críticas negativas en los items que no les gustan. Con estos dos tipos de usuarios, principalmente con el segundo, se crearía un problema al recomendarle items a estos.

En cuanto a estructura, el paper tenía una muy fácil de seguir: Introducción general a los CF y conceptos, seguido por los diferentes tipos de algoritmos en subcategorías de CFs, y finalmente su uso aplicado y parámetros para medir sus resultados. Un ejemplo del uso aplicado sería el qué hacer en los "cold cases", que significa usuarios que no han calificado ningún item todavía. Y un ejemplo de parámetros puede ser la matriz de confianza, que compara predicción vs. realidad, con el fin de ver la precisión de cada sistema. Al tener una estructura tan bien hecha, el paper se hizo más ligero de leer.

En resumen, fue un paper completo en cuanto a listar los diferentes algoritmos, tomar en consideración los posibles errores humanos y las preocupaciones con cada algoritmo y dar una posible solución dentro de los mismos algoritmos.